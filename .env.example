# ===========================================
# FairShare Configuration Template
# ===========================================
# Copy this file to .env.local and fill in your values

# ------------------------------------------
# Document Parsing Service (Python/Docling)
# ------------------------------------------
DOCLING_SERVICE_URL=http://localhost:8000

# ------------------------------------------
# Ollama Configuration (Local LLM - Primary)
# ------------------------------------------
# URL where Ollama is running
OLLAMA_BASE_URL=http://localhost:11434

# Model to use for bill extraction
# Options: llama3:8b, llama3.2, mistral, etc.
OLLAMA_MODEL=llama3:8b

# ------------------------------------------
# Perplexity API (Fallback when Ollama fails)
# ------------------------------------------
# Get your API key from: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=
